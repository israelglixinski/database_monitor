# oracle.py
from dotenv import load_dotenv
import oracledb
import os
import time
import random
import string
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import argparse
from contextlib import contextmanager

load_dotenv()

ORACLE_HOST = os.getenv('ORACLE_HOST')
ORACLE_PORT = os.getenv('ORACLE_PORT', '1521')
ORACLE_BASE = os.getenv('ORACLE_BASE')
ORACLE_USER = os.getenv('ORACLE_USER')
ORACLE_PASS = os.getenv('ORACLE_PASS')

DSN = f"{ORACLE_HOST}:{ORACLE_PORT}/{ORACLE_BASE}"

# ---------- conexão ----------
def connect():
    """
    Abre uma conexão Thin (não precisa client nativo).
    Cada thread deve abrir sua própria conexão.
    """
    conn = oracledb.connect(user=ORACLE_USER, password=ORACLE_PASS, dsn=DSN)
    return conn

def test_connection():
    with connect() as conn:
        with conn.cursor() as cur:
            cur.execute("select systimestamp from dual")
            return cur.fetchall()

# ---------- util ----------
def _rand_text(n=12):
    return ''.join(random.choices(string.ascii_letters + string.digits, k=n))

def _exec_ddl(cur, sql):
    try:
        cur.execute(sql)
    except oracledb.DatabaseError as e:
        # Ignora erros comuns de objeto já existente
        msg = str(e)
        if any(code in msg for code in ["ORA-00955", "ORA-00942", "ORA-01418", "ORA-04043"]):
            pass
        else:
            raise

@contextmanager
def _cursor(conn=None):
    own = False
    if conn is None:
        conn = connect()
        own = True
    cur = conn.cursor()
    try:
        yield cur
    finally:
        cur.close()
        if own:
            conn.close()

# ---------- bootstrap do schema ----------
DDL_TABLES = [
    # Clientes
    """
    CREATE TABLE STRESS_CUSTOMER(
        ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        NAME VARCHAR2(100),
        EMAIL VARCHAR2(150),
        CREATED_AT TIMESTAMP DEFAULT SYSTIMESTAMP
    )
    """,
    # Produtos
    """
    CREATE TABLE STRESS_PRODUCT(
        ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        NAME VARCHAR2(120),
        PRICE NUMBER(10,2),
        CREATED_AT TIMESTAMP DEFAULT SYSTIMESTAMP
    )
    """,
    # Pedidos
    """
    CREATE TABLE STRESS_ORDER(
        ID NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        CUSTOMER_ID NUMBER NOT NULL,
        PRODUCT_ID  NUMBER NOT NULL,
        QTY NUMBER(10) NOT NULL,
        NOTES CLOB,
        CREATED_AT TIMESTAMP DEFAULT SYSTIMESTAMP,
        CONSTRAINT FK_ORDER_CUSTOMER FOREIGN KEY (CUSTOMER_ID) REFERENCES STRESS_CUSTOMER(ID),
        CONSTRAINT FK_ORDER_PRODUCT  FOREIGN KEY (PRODUCT_ID)  REFERENCES STRESS_PRODUCT(ID)
    )
    """,
]

DDL_INDEXES = [
    "CREATE INDEX IDX_ORDER_CUST ON STRESS_ORDER(CUSTOMER_ID)",
    "CREATE INDEX IDX_ORDER_PROD ON STRESS_ORDER(PRODUCT_ID)",
    "CREATE INDEX IDX_PRODUCT_PRICE ON STRESS_PRODUCT(PRICE)"
]

# Uma procedure simples para leituras aleatórias do lado do banco
PLSQL_SP_RANDOM_READS = """
CREATE OR REPLACE PROCEDURE SP_STRESS_RANDOM_READS(p_loops IN NUMBER) AS
    v_count NUMBER;
    v_cust NUMBER;
BEGIN
    FOR i IN 1..p_loops LOOP
        v_cust := TRUNC(DBMS_RANDOM.VALUE(1, 10000)); -- assume pelo menos 10k clientes em cenários maiores
        SELECT COUNT(*) INTO v_count
          FROM STRESS_ORDER
         WHERE CUSTOMER_ID = v_cust;
    END LOOP;
END;
"""

def init_schema():
    with connect() as conn, _cursor(conn) as cur:
        for ddl in DDL_TABLES:
            _exec_ddl(cur, ddl)
        for ddl in DDL_INDEXES:
            _exec_ddl(cur, ddl)
        _exec_ddl(cur, PLSQL_SP_RANDOM_READS)
        conn.commit()
    print("Schema de teste pronto (tabelas/índices/procedure).")

# ---------- geradores de dados ----------
def seed_products(n=1000, batch=500):
    with connect() as conn, _cursor(conn) as cur:
        total = 0
        while total < n:
            k = min(batch, n - total)
            rows = [(f"Product {_rand_text(8)}", round(random.uniform(1, 5000), 2))
                    for _ in range(k)]
            cur.executemany(
                "INSERT INTO STRESS_PRODUCT(NAME, PRICE) VALUES (:1, :2)",
                rows
            )
            total += k
        conn.commit()
    print(f"Seed: {n} produtos inseridos.")

def seed_customers(n=10000, batch=1000):
    with connect() as conn, _cursor(conn) as cur:
        total = 0
        while total < n:
            k = min(batch, n - total)
            rows = [(f"Customer {_rand_text(10)}", f"{_rand_text(6)}@mail.test")
                    for _ in range(k)]
            cur.executemany(
                "INSERT INTO STRESS_CUSTOMER(NAME, EMAIL) VALUES (:1, :2)",
                rows
            )
            total += k
        conn.commit()
    print(f"Seed: {n} clientes inseridos.")

# ---------- operações de workload ----------
def insert_orders(conn, n_rows=5000, batch=1000):
    with _cursor(conn) as cur:
        # Descobre faixas de IDs para sortear chaves válidas
        cur.execute("SELECT NVL(MIN(ID),1), NVL(MAX(ID),1) FROM STRESS_CUSTOMER")
        c_min, c_max = cur.fetchone()
        cur.execute("SELECT NVL(MIN(ID),1), NVL(MAX(ID),1) FROM STRESS_PRODUCT")
        p_min, p_max = cur.fetchone()

        total = 0
        while total < n_rows:
            k = min(batch, n_rows - total)
            rows = []
            for _ in range(k):
                cust = random.randint(c_min, c_max)
                prod = random.randint(p_min, p_max)
                qty  = random.randint(1, 10)
                note = "NOTE " + _rand_text(50)
                rows.append((cust, prod, qty, note))
            cur.executemany(
                "INSERT /*+ APPEND */ INTO STRESS_ORDER(CUSTOMER_ID, PRODUCT_ID, QTY, NOTES) VALUES (:1,:2,:3,:4)",
                rows
            )
            total += k
        conn.commit()
    return total

def random_reads(conn, iterations=10000):
    with _cursor(conn) as cur:
        # prefere a procedure (rodando no banco); se não existir, faz fallback em SQL
        try:
            cur.callproc("SP_STRESS_RANDOM_READS", [iterations])
        except oracledb.DatabaseError:
            for _ in range(iterations):
                cust = random.randint(1, 10000)
                cur.execute("SELECT COUNT(*) FROM STRESS_ORDER WHERE CUSTOMER_ID = :1",
                            (cust,))
                _ = cur.fetchone()[0]

def random_updates(conn, iterations=2000):
    with _cursor(conn) as cur:
        for _ in range(iterations):
            # atualiza qty aleatoriamente em uma amostra
            cur.execute("""
                UPDATE STRESS_ORDER
                   SET QTY = QTY + 1
                 WHERE ID IN (
                     SELECT ID FROM STRESS_ORDER
                      WHERE ROWNUM <= 50
                 )
            """)
        conn.commit()

# ---------- orquestração do estresse ----------
def run_workload(minutes=2, workers=6,
                 insert_ratio=0.5, read_ratio=0.35, update_ratio=0.15,
                 insert_batch=2000):
    ratios = [('insert', insert_ratio), ('read', read_ratio), ('update', update_ratio)]
    total = sum(r for _, r in ratios)
    ratios = [(k, r/total) for k, r in ratios]

    stop_at = datetime.now() + timedelta(minutes=minutes)
    stats = {'insert': 0, 'read': 0, 'update': 0}

    def worker_loop():
        conn = connect()
        try:
            while datetime.now() < stop_at:
                r = random.random()
                if r < ratios[0][1]:
                    cnt = insert_orders(conn, n_rows=insert_batch, batch=1000)
                    stats['insert'] += cnt
                elif r < ratios[0][1] + ratios[1][1]:
                    random_reads(conn, iterations=5000)
                    stats['read'] += 5000
                else:
                    random_updates(conn, iterations=500)
                    stats['update'] += 500
        finally:
            conn.close()

    with ThreadPoolExecutor(max_workers=workers) as ex:
        futs = [ex.submit(worker_loop) for _ in range(workers)]
        for _ in as_completed(futs):
            pass

    print("Workload finalizado.")
    print(f"Totais aproximados: inserts={stats['insert']}, reads={stats['read']}, updates={stats['update']}")

# ---------- monitor ----------
MONITOR_QUERIES = [
    # Sessões ativas por classe de espera
    ("sessions_by_wait",
     """
     SELECT NVL(wait_class, 'CPU') AS wait_class, COUNT(*) AS cnt
       FROM v$session
      WHERE type = 'USER'
      GROUP BY NVL(wait_class, 'CPU')
      ORDER BY cnt DESC
     """),
    # Top eventos de espera atuais
    ("top_wait_events",
     """
     SELECT * FROM (
        SELECT event, COUNT(*) AS cnt
          FROM v$session
         WHERE state='WAITING'
         GROUP BY event
         ORDER BY cnt DESC
     ) WHERE ROWNUM <= 10
     """),
    # Top SQL por tempo acumulado
    ("top_sql_elapsed",
     """
     SELECT * FROM (
        SELECT sql_id,
               ROUND(elapsed_time/1e6,2) AS elapsed_s,
               ROUND(cpu_time/1e6,2)     AS cpu_s,
               executions,
               SUBSTR(sql_text,1,80) AS sql_text
          FROM v$sqlarea
         WHERE executions > 0
         ORDER BY elapsed_time DESC
     ) WHERE ROWNUM <= 10
     """),
    # Segmentos mais lidos/modificados
    ("hot_segments",
     """
     SELECT * FROM (
        SELECT owner, object_name, subobject_name, statistic_name, value
          FROM v$segment_statistics
         WHERE statistic_name IN ('logical reads','physical reads','db block changes','ITL waits')
         ORDER BY value DESC
     ) WHERE ROWNUM <= 10
     """),
]

# Fallbacks quando não há privilégio em v$
FALLBACK_QUERIES = [
    ("my_sessions",  # pouca utilidade, mas mostra sua própria sessão
     "SELECT SID, SERIAL#, STATUS, MODULE FROM v$session WHERE AUDSID = USERENV('SESSIONID')"),
    ("user_tables_tops",
     """
     SELECT table_name, num_rows
       FROM user_tables
      ORDER BY NVL(num_rows,0) DESC FETCH FIRST 10 ROWS ONLY
     """),
    ("recent_objects",
     """
     SELECT object_name, object_type, created
       FROM user_objects
      ORDER BY created DESC FETCH FIRST 10 ROWS ONLY
     """),
]

def monitor_db(seconds=60, every=3):
    """
    Tira snapshots a cada `every` segundos durante `seconds`.
    Tenta v$*; se der falta de privilégio, usa fallbacks.
    """
    end = time.time() + seconds
    snap = 0
    while time.time() < end:
        snap += 1
        print(f"\n=== Snapshot {snap} @ {datetime.now().strftime('%H:%M:%S')} ===")
        with connect() as conn, _cursor(conn) as cur:
            # Primeiro tenta as queries de monitor
            used_fallback = False
            for name, q in MONITOR_QUERIES:
                try:
                    cur.execute(q)
                    rows = cur.fetchall()
                    cols = [d[0] for d in cur.description]
                    print(f"\n[{name}]")
                    _print_table(cols, rows, limit=10)
                except oracledb.DatabaseError as e:
                    if not used_fallback:
                        print("\n(sem privilégios para v$*, usando métricas alternativas)")
                        used_fallback = True
                    # executa apenas uma vez os fallbacks
            if used_fallback:
                for name, q in FALLBACK_QUERIES:
                    try:
                        cur.execute(q)
                        rows = cur.fetchall()
                        cols = [d[0] for d in cur.description]
                        print(f"\n[{name}]")
                        _print_table(cols, rows, limit=10)
                    except Exception:
                        pass
        time.sleep(every)

def _print_table(cols, rows, limit=10):
    # impressão simples e compacta
    if not rows:
        print("(sem linhas)")
        return
    rows = rows[:limit]
    widths = [len(c) for c in cols]
    for r in rows:
        widths = [max(widths[i], len(str(r[i]) if r[i] is not None else "")) for i in range(len(cols))]
    fmt = " | ".join("{:<" + str(w) + "}" for w in widths)
    print(fmt.format(*cols))
    print("-+-".join("-" * w for w in widths))
    for r in rows:
        print(fmt.format(*[("" if v is None else str(v)) for v in r]))

# ---------- CLI ----------
def main():
    parser = argparse.ArgumentParser(description="Oracle stress & monitor kit")
    sub = parser.add_subparsers(dest="cmd")

    sub.add_parser("ping", help="Testa conexão e imprime SYSTIMESTAMP")

    p_init = sub.add_parser("init", help="Cria tabelas/índices/procedure de teste")
    p_init.add_argument("--seed-products", type=int, default=1000)
    p_init.add_argument("--seed-customers", type=int, default=10000)

    p_work = sub.add_parser("workload", help="Roda workload de estresse")
    p_work.add_argument("--minutes", type=int, default=2)
    p_work.add_argument("--workers", type=int, default=6)
    p_work.add_argument("--insert-batch", type=int, default=2000)
    p_work.add_argument("--mix", type=str, default="0.5,0.35,0.15",
                        help="proporções insert,read,update (ex: 0.6,0.3,0.1)")

    p_mon = sub.add_parser("monitor", help="Monitora gargalos")
    p_mon.add_argument("--seconds", type=int, default=60)
    p_mon.add_argument("--every", type=int, default=3)

    args = parser.parse_args()

    if args.cmd == "ping":
        print(test_connection())
    elif args.cmd == "init":
        init_schema()
        if args.seed_products > 0:
            seed_products(args.seed_products)
        if args.seed_customers > 0:
            seed_customers(args.seed_customers)
    elif args.cmd == "workload":
        a,b,c = [float(x) for x in args.mix.split(",")]
        run_workload(minutes=args.minutes, workers=args.workers,
                     insert_ratio=a, read_ratio=b, update_ratio=c,
                     insert_batch=args.insert_batch)
    elif args.cmd == "monitor":
        monitor_db(seconds=args.seconds, every=args.every)
    else:
        # comportamento padrão: só ping
        print(test_connection())

if __name__ == "__main__":
    main()
